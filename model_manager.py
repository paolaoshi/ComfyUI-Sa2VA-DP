# Sa2VA æ¨¡å‹ä¸‹è½½å’Œç®¡ç†å™¨
# è´Ÿè´£è‡ªåŠ¨ä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•ï¼Œå¹¶æ£€æµ‹å·²å­˜åœ¨çš„æ¨¡å‹

import os
import torch
from pathlib import Path
from typing import Optional, Tuple


class Sa2VAModelManager:
    """Sa2VAæ¨¡å‹ç®¡ç†å™¨ - å¤„ç†æ¨¡å‹ä¸‹è½½å’Œç¼“å­˜"""
    
    def __init__(self, comfyui_path: str = "E:/Comfyui_test/ComfyUI"):
        """
        åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
        
        Args:
            comfyui_path: ComfyUIçš„æ ¹ç›®å½•è·¯å¾„
        """
        self.comfyui_path = Path(comfyui_path)
        # æ¨¡å‹å­˜å‚¨ç›®å½•ï¼šComfyUI/models/Sa2VA
        self.models_dir = self.comfyui_path / "models" / "Sa2VA"
        
        # ç¡®ä¿æ¨¡å‹ç›®å½•å­˜åœ¨
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“ Sa2VAæ¨¡å‹ç›®å½•: {self.models_dir}")
    
    def get_model_path(self, model_name: str) -> Path:
        """
        è·å–æ¨¡å‹çš„æœ¬åœ°å­˜å‚¨è·¯å¾„
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œä¾‹å¦‚ "ByteDance/Sa2VA-Qwen3-VL-4B"
        
        Returns:
            æ¨¡å‹çš„æœ¬åœ°è·¯å¾„
        """
        # ä»å®Œæ•´åç§°ä¸­æå–æ¨¡å‹ç®€ç§°
        # ä¾‹å¦‚: "ByteDance/Sa2VA-Qwen3-VL-4B" -> "Sa2VA-Qwen3-VL-4B"
        model_short_name = model_name.split("/")[-1]
        return self.models_dir / model_short_name
    
    def is_model_downloaded(self, model_name: str) -> bool:
        """
        æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç»ä¸‹è½½
        
        Args:
            model_name: æ¨¡å‹åç§°
        
        Returns:
            Trueå¦‚æœæ¨¡å‹å·²ä¸‹è½½ï¼ŒFalseå¦åˆ™
        """
        model_path = self.get_model_path(model_name)
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not model_path.exists():
            return False
        
        # æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        # Sa2VAæ¨¡å‹é€šå¸¸åŒ…å«è¿™äº›æ–‡ä»¶
        required_files = [
            "config.json",           # æ¨¡å‹é…ç½®
            "model.safetensors",     # æ¨¡å‹æƒé‡ï¼ˆsafetensorsæ ¼å¼ï¼‰
        ]
        
        # ä¹Ÿå¯èƒ½æ˜¯pytorchæ ¼å¼
        alternative_files = [
            "pytorch_model.bin",     # æ¨¡å‹æƒé‡ï¼ˆpytorchæ ¼å¼ï¼‰
        ]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¿…éœ€çš„é…ç½®æ–‡ä»¶
        has_config = (model_path / "config.json").exists()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹æƒé‡æ–‡ä»¶ï¼ˆsafetensorsæˆ–pytorchæ ¼å¼ï¼‰
        has_weights = (
            (model_path / "model.safetensors").exists() or
            (model_path / "pytorch_model.bin").exists() or
            any((model_path / f"model-{i:05d}-of-*.safetensors").exists() 
                for i in range(1, 100))  # åˆ†ç‰‡æ¨¡å‹
        )
        
        if has_config and has_weights:
            print(f"âœ… æ£€æµ‹åˆ°å·²ä¸‹è½½çš„æ¨¡å‹: {model_path}")
            return True
        
        return False
    
    def download_model(
        self, 
        model_name: str, 
        force_download: bool = False
    ) -> Tuple[bool, str]:
        """
        ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ç›®å½•
        
        Args:
            model_name: HuggingFaceæ¨¡å‹åç§°
            force_download: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
        
        Returns:
            (æˆåŠŸæ ‡å¿—, æ¨¡å‹æœ¬åœ°è·¯å¾„æˆ–é”™è¯¯ä¿¡æ¯)
        """
        try:
            model_path = self.get_model_path(model_name)
            
            # å¦‚æœæ¨¡å‹å·²å­˜åœ¨ä¸”ä¸å¼ºåˆ¶ä¸‹è½½ï¼Œç›´æ¥è¿”å›
            if not force_download and self.is_model_downloaded(model_name):
                print(f"âœ… æ¨¡å‹å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {model_path}")
                return True, str(model_path)
            
            print(f"ğŸ”„ å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_name}")
            print(f"ğŸ“¥ ä¸‹è½½ç›®æ ‡ç›®å½•: {model_path}")
            
            # ä½¿ç”¨huggingface_hubä¸‹è½½æ¨¡å‹
            from huggingface_hub import snapshot_download
            
            # ä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•
            downloaded_path = snapshot_download(
                repo_id=model_name,
                local_dir=str(model_path),
                local_dir_use_symlinks=False,  # ä¸ä½¿ç”¨ç¬¦å·é“¾æ¥ï¼Œç›´æ¥å¤åˆ¶æ–‡ä»¶
                resume_download=True,          # æ”¯æŒæ–­ç‚¹ç»­ä¼ 
                max_workers=4,                 # å¹¶è¡Œä¸‹è½½çº¿ç¨‹æ•°
            )
            
            print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {downloaded_path}")
            return True, str(model_path)
            
        except Exception as e:
            error_msg = f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {str(e)}"
            print(error_msg)
            return False, error_msg
    
    def get_model_info(self, model_name: str) -> dict:
        """
        è·å–æ¨¡å‹ä¿¡æ¯
        
        Args:
            model_name: æ¨¡å‹åç§°
        
        Returns:
            åŒ…å«æ¨¡å‹ä¿¡æ¯çš„å­—å…¸
        """
        model_path = self.get_model_path(model_name)
        
        info = {
            "name": model_name,
            "local_path": str(model_path),
            "downloaded": self.is_model_downloaded(model_name),
            "exists": model_path.exists(),
        }
        
        # å¦‚æœæ¨¡å‹å·²ä¸‹è½½ï¼Œè·å–æ›´å¤šä¿¡æ¯
        if info["downloaded"]:
            try:
                # è®¡ç®—æ¨¡å‹å¤§å°
                total_size = 0
                for file_path in model_path.rglob("*"):
                    if file_path.is_file():
                        total_size += file_path.stat().st_size
                
                info["size_gb"] = total_size / (1024 ** 3)  # è½¬æ¢ä¸ºGB
                
                # åˆ—å‡ºä¸»è¦æ–‡ä»¶
                info["files"] = [f.name for f in model_path.iterdir() if f.is_file()]
                
            except Exception as e:
                info["error"] = str(e)
        
        return info
    
    def list_downloaded_models(self) -> list:
        """
        åˆ—å‡ºæ‰€æœ‰å·²ä¸‹è½½çš„æ¨¡å‹
        
        Returns:
            å·²ä¸‹è½½æ¨¡å‹çš„åˆ—è¡¨
        """
        if not self.models_dir.exists():
            return []
        
        downloaded = []
        for model_dir in self.models_dir.iterdir():
            if model_dir.is_dir():
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æ¨¡å‹ç›®å½•
                if (model_dir / "config.json").exists():
                    downloaded.append(model_dir.name)
        
        return downloaded
    
    def clear_cache(self, model_name: Optional[str] = None):
        """
        æ¸…é™¤æ¨¡å‹ç¼“å­˜
        
        Args:
            model_name: è¦æ¸…é™¤çš„æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™æ¸…é™¤æ‰€æœ‰
        """
        if model_name:
            model_path = self.get_model_path(model_name)
            if model_path.exists():
                import shutil
                shutil.rmtree(model_path)
                print(f"ğŸ—‘ï¸ å·²æ¸…é™¤æ¨¡å‹ç¼“å­˜: {model_path}")
        else:
            if self.models_dir.exists():
                import shutil
                shutil.rmtree(self.models_dir)
                self.models_dir.mkdir(parents=True, exist_ok=True)
                print(f"ğŸ—‘ï¸ å·²æ¸…é™¤æ‰€æœ‰æ¨¡å‹ç¼“å­˜")


# å…¨å±€æ¨¡å‹ç®¡ç†å™¨å®ä¾‹
_global_model_manager = None


def get_model_manager(comfyui_path: str = "E:/Comfyui_test/ComfyUI") -> Sa2VAModelManager:
    """
    è·å–å…¨å±€æ¨¡å‹ç®¡ç†å™¨å®ä¾‹
    
    Args:
        comfyui_path: ComfyUIæ ¹ç›®å½•è·¯å¾„
    
    Returns:
        æ¨¡å‹ç®¡ç†å™¨å®ä¾‹
    """
    global _global_model_manager
    if _global_model_manager is None:
        _global_model_manager = Sa2VAModelManager(comfyui_path)
    return _global_model_manager
